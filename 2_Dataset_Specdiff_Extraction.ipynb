{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. Dataset Specdiff Extraction",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o5MjsV4q1Rmt",
        "outputId": "9d795aa8-d060-4b6d-efb2-edc8344b355f"
      },
      "source": [
        "cd /content/drive/MyDrive/MBKM RISET/RISET_1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/MBKM RISET/RISET_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qy7HyEkjVtNG"
      },
      "source": [
        "## Loading Images in Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gj2Zd7xj2QB6"
      },
      "source": [
        "import os\n",
        "path_live = \"/content/drive/MyDrive/MBKM RISET/RISET_1/SpecDiff_in_house_database_sample/data/live\"\n",
        "path_spoof = \"/content/drive/MyDrive/MBKM RISET/RISET_1/SpecDiff_in_house_database_sample/data/spoof\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MNFYCGxK3oJV"
      },
      "source": [
        "def load_images(path):\n",
        "  image_path_flash = []\n",
        "  image_path_background = []\n",
        "  for file_id in os.listdir(path):\n",
        "    id = os.path.join(path,file_id)\n",
        "    counter = True\n",
        "    for filename in os.listdir(id):\n",
        "      if counter == True:\n",
        "        image_path_background.append(os.path.join(id, filename))\n",
        "        counter = False\n",
        "      elif counter == False: \n",
        "        image_path_flash.append(os.path.join(id, filename))\n",
        "        counter = True\n",
        "  return image_path_flash,image_path_background"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n_3nFkmY7kpv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "24dc126c-85f6-4fbf-9078-da0e1268d036"
      },
      "source": [
        "live_flash,live_bg = load_images(path_live)\n",
        "spoof_flash,spoof_bg = load_images(path_spoof)\n",
        "sum_live = len(live_flash)+len(live_bg)\n",
        "sum_spoof = len(spoof_flash)+len(spoof_bg)\n",
        "print(\"Jumlah Pasangan Gambar Live : \" + str(sum_live/2))\n",
        "print(\"Jumlah Pasangan Gambar Spoof : \" + str(sum_spoof/2))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah Pasangan Gambar Live : 240.0\n",
            "Jumlah Pasangan Gambar Spoof : 336.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqF_px2RVEwx"
      },
      "source": [
        "print(live_flash[0:10])\n",
        "print(live_bg[0:10])\n",
        "print(spoof_flash[0:10])\n",
        "print(spoof_bg[0:10])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m0pQOFkaV5jq"
      },
      "source": [
        "## Library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMgeiFBuV4NZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d67dd53c-ed4c-4014-c626-cb755deec676"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://raw.githubusercontent.com/italojs/facial-landmarks-recognition/master/shape_predictor_68_face_landmarks.dat \\\n",
        "    -O shape_predictor_68_face_landmarks.dat\n",
        "    \n",
        "from imutils import face_utils\n",
        "import imutils\n",
        "import numpy as np\n",
        "import collections\n",
        "import dlib\n",
        "import cv2\n",
        "\n",
        "%matplotlib inline \n",
        "from matplotlib import pyplot as plt \n",
        "import pylab \n",
        "pylab.rcParams['figure.figsize'] = (10.0, 8.0)\n",
        "\n",
        "detector = dlib.get_frontal_face_detector()\n",
        "predictor = dlib.shape_predictor('shape_predictor_68_face_landmarks.dat')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-29 06:55:56--  https://raw.githubusercontent.com/italojs/facial-landmarks-recognition/master/shape_predictor_68_face_landmarks.dat\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 99693937 (95M) [application/octet-stream]\n",
            "Saving to: ‘shape_predictor_68_face_landmarks.dat’\n",
            "\n",
            "shape_predictor_68_ 100%[===================>]  95.08M  60.8MB/s    in 1.6s    \n",
            "\n",
            "2021-10-29 06:56:01 (60.8 MB/s) - ‘shape_predictor_68_face_landmarks.dat’ saved [99693937/99693937]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Function"
      ],
      "metadata": {
        "id": "CKlNkuvDlem6"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMALJhO-W52A"
      },
      "source": [
        "base_path = \"/content/drive/MyDrive/MBKM RISET/\"\n",
        "\n",
        "def cropping(image):\n",
        "  try:\n",
        "    rect = detector(image)[0]\n",
        "  except (ValueError,IndexError):\n",
        "    print(\"Not Found Face!!\")\n",
        "    return image\n",
        "  sp = predictor(image, rect)\n",
        "  landmarks = np.array([[p.x, p.y] for p in sp.parts()])\n",
        "  x = []\n",
        "  y_alis = []\n",
        "  y = []\n",
        "  w = []\n",
        "  h = []\n",
        "\n",
        "  x.append(landmarks[1][0])\n",
        "  y_alis.append(landmarks[17][1])\n",
        "  y_alis.append(landmarks[18][1])\n",
        "  y_alis.append(landmarks[23][1])\n",
        "  y_alis.append(landmarks[24][1])\n",
        "  w.append(landmarks[15][0])\n",
        "  h.append(landmarks[8][1])\n",
        "  y.append(min(y_alis))\n",
        "\n",
        "  crop_img = image[y[0]:h[0], x[0]:w[0]]\n",
        "  \n",
        "  return crop_img\n",
        "\n",
        "\n",
        "def preprocessing (path,sig,size_x,size_y):\n",
        "  #face_pre = []\n",
        "  #face = []\n",
        "  global face_pre,crop_img\n",
        "  base_image = cv2.imread(path)\n",
        "  if(base_image is not None):\n",
        "    grey = cv2.cvtColor(base_image, cv2.COLOR_BGR2GRAY)\n",
        "    #for (x, y, w, h) in faces:\n",
        "      #crop_img = grey[y:y + h, x:x + w]\n",
        "    #crop_img = grey[faces[0,1]:faces[0,1]+faces[0,3], faces[0,0]:faces[0,0]+faces[0,3]]\n",
        "    crop_img = cropping(grey)\n",
        "    face_pre = cv2.GaussianBlur(crop_img, ksize=(0, 0), sigmaX=sig, borderType=cv2.BORDER_REPLICATE)\n",
        "    face = np.double(cv2.resize(np.array(face_pre),(size_x,size_y)))\n",
        "  return face\n",
        "\n",
        "def feature(flash,background):\n",
        "  a = flash - background\n",
        "  b = flash + background\n",
        "  c = a/b\n",
        "  trans = np.transpose(c)\n",
        "  feat_vec = np.reshape(trans, (1, trans.size))\n",
        "  feat_vec = np.nan_to_num(feat_vec)\n",
        "  return feat_vec\n",
        "\n",
        "def diffuse_extract(output,path_flash,path_bg):\n",
        "  output_folder = output\n",
        "  if not os.path.exists(output_folder):\n",
        "    os.makedirs(output_folder)\n",
        "  for i in range(len(path_flash)): #range(20):  #range(len(path_flash)):\n",
        "    flash = preprocessing(path_flash[i],5,100,100)\n",
        "    background = preprocessing(path_bg[i],5,100,100)\n",
        "    pantulan = feature(flash,background)\n",
        "    name = os.path.join(base_path,output_folder,str(i)+'.JPG')\n",
        "    print(name)\n",
        "    plt.imsave(name, pantulan, cmap='gray')\n",
        "\n",
        "def save_images(path_flash,path_bg,file_name):\n",
        "  feature_label = []\n",
        "  for i in range(len(path_flash)):\n",
        "    flash = preprocessing(path_flash[i],5,100,100)\n",
        "    background = preprocessing(path_bg[i],5,100,100)\n",
        "    pantulan = feature(flash,background)\n",
        "    print(path_flash[i])\n",
        "    label = 0\n",
        "    feature_label.append(np.append(pantulan,np.array(label)))\n",
        "    np.save(file_name,np.array(feature_label))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Build .npy dataset file"
      ],
      "metadata": {
        "id": "u0dvHQK0lg8i"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hXvO9NFoKeIx"
      },
      "source": [
        "save_images(live_flash,live_bg,\"live.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixcw6uNyK1Fh"
      },
      "source": [
        "save_images(spoof_flash,spoof_bg,\"spoof.npy\")"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}